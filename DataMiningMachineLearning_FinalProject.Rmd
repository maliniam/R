---
title: "Data Mining & Machine Learning: Final Project"
author: "A. Malinish"
date: "12/10/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Section 1: Supervised Learning
## Logistic Regression

```{r}
df = read.csv("Heart.csv") # reading data saved in Working Directory and assigning to data.frame df
str(df) # displays structure of data frame df
df$AHD = factor(df$AHD) # to convert variable AHD from character to factor
names(df) # displays names of columns of df 
summary(df) # summarizes data
attach(df) # attaching df to R's search path
set.seed(872020)
train = sample(1:303, size = 203, replace = FALSE) # Question 3.1: What does this line of code do?
df_train = df[train,] # Question 3.2: Is this training set a random sample from the original data df? How many rows does it have?
df_test = df[-train,] # Question 3.3: How many rows does this test set have?
# Logistic Regression
glm.fit = glm(AHD ~ ., data = df_train, family = binomial) 
summary(glm.fit) # Question 3.4: What does this line of code produce? Write a summary about the output. [Hint: Read Sections 4.3.4 and 4.6.2 from the book]
glm.probs = predict(glm.fit, type = "response", newdata = df_test) # Question 3.5: What does this line of code produce? 
glm.pred = ifelse(glm.probs > 0.5, "Yes", "No") # Question 3.6: What does this line of code do?
table(Predicted = glm.pred, Actual = df_test$AHD) # Question 3.7: What does this line of code produce? What is this table called?
mean(glm.pred == df_test$AHD, na.rm=T) # Question 3.8: What does this number denote?

```
## Logistic Regression Summary of Output

### Question 3.1

This line of code generates a random sample of size 203 using the numbers 1-303, without replacement of the values, and stores it as the RObject, "train".

### Question 3.2

This training set is a random sample of the original data, df. This line of code matched the values of the train RObject with the corresponding observation numbers in the df dataframe, producing a new dataframe name df_train. There are a total of 203 rows in the new dataframe. This dataframe will serve as the training dataset.

### Question 3.3

This line of code produces a dataframe from the original using the remaining values that are left after separating out the training set in the previous step. This results in a dataframe, named df_test, with 100 rows. This dataset will serve as the test dataset.

### Question 3.4

This line of code produces the summary output of the logistic regression model, glm.fit, produced in the previous step using the training dataset. The summary produced includes the coefficient values for each variable included in the model. From this summary, we can see that only the variables Sex, ChestPainnonanginal, ChestPaintypical, Slope, and Ca are significant predictors of AHD in the model.

### Question 3.5

This line of code predicts the probability that AHD = "Yes" (based on the glm.fit model that was trained using the df_train datatset) according to the values of all other variables for each observation of the test dataset. This output is stored as glm.probs.

### Question 3.6

This line of code assigns the label "Yes" to all values of glm.probs that are > 0.50 and all other values to "No". Yes or no in this case represents the predicted occurrence of AHD for each observation of the test dataset, given all other variable values. These results are stored as the RObject glm.pred.

### Question 3.7

This line of code arranges predicted AHD response values (determined using the training dataset in the glm.fit model) against actual values obtained using the test dataset. This table is known as a confusion matrix.

### Question 3.8

This line of code generates the accuracy of the AHD predictions produced for the test data. In this case, the glm.fit model produced an accurate prediction 84.5% of the time.


## Tree Based Classification

```{r}
library(tree) 
df = read.csv("Heart.csv")
df$AHD = factor(df$AHD)
attach(df)
df.tree <- tree(AHD ~., df)
summary(df.tree)

plot(df.tree)
text(df.tree, pretty = 0)
df.tree

set.seed(872020)
train = sample(1:303, size = 203, replace = FALSE)
train_data = df[train,]
test_data <- df[-train,]
tree.train <- tree(AHD ~., train_data)
tree.pred <- predict (tree.train, test_data, type = "class")
table(Predicted = tree.pred, Actual = test_data$AHD)

(45+36)/100
```
## Tress Classification Summary of Output

This R chunk code results in the production of a classification tree (without pruning) for the df (Heart) dataset. The initial classification tree produces a misclassification error rate of 12.8%. The tree model is trained using the train_data subset, and is subsequently tested on the test_data subset. The testing of the model yields a classification accurracy rate of 81% and a misclassification error rate of 19%. This is higher than the initial misclassification error rate, however that is expected to occur for model testing as the training model is known to overfit the data.

## Best Subset Selection Method for Regression
```{r}
library(MASS) # MASS package must be installed
library(leaps) # leaps package must be installed 
attach(Boston) # attaching Boston data to Râ€™s search path 
str(Boston) # displays structure of data.
names(Boston) # shows names of columns (variables) of Boston data set. To know more about this data set, you may type ?Boston in the R Console window.
regfit.full = regsubsets(medv~., data = Boston, nvmax = 13) # Question 4.1: What does this line of code do? Why do we use nvmax = 13 in this code?
summary(regfit.full) # Question 4.2: What does this line of code print? Which variables are included in the best eight-variable model?
reg.summary = summary(regfit.full)
names(reg.summary) # Question 4.3: What does this line of code print?
reg.summary$rsq
par(mfrow = c(2,2)) # Question 4.4: What does this line of code do?
plot(reg.summary$rss, xlab = "Number of Variables", ylab = " RSS", type = "l", col="red")
plot(reg.summary$adjr2, xlab = "Number of Variables", ylab= "Adjusted RSq", type = "l", col="red")
plot(reg.summary$cp, xlab = "Number of Variables", ylab = "Mallow's Cp", type = "l", col="red")
plot(reg.summary$bic, xlab = "Number of Variables", ylab= "BIC", type = "l", col="red")
# Question 4.5: What is the result of running the four plots?
which.max(reg.summary$adjr2) # Question 4.6: What does this line of code print? What does it denote?
which.min(reg.summary$cp) # Question 4.7: What does this line of code print? What does it denote?
which.min(reg.summary$bic) # Question 4.8: What does this line of code print? What does it denote?
par(mfrow = c(1,1))
plot(regfit.full, scale = "r2")
plot(regfit.full, scale = "adjr2")
plot(regfit.full, scale = "Cp")
plot(regfit.full, scale = "bic")
# Question 4.9: What is the result of running the four plots? Explain what these plots denote.
# Question 4.10: Using answers to Questions 4.6 through 4.8, which model is considered the best model?

regfit.fwd <- regsubsets (medv ~ ., data = Boston, nvmax = 13, method = "forward")
summary (regfit.fwd)
regfit.bwd <- regsubsets (medv ~ ., data = Boston, nvmax = 13, method = "backward")
summary (regfit.bwd)

coef(regfit.fwd, 11)
coef(regfit.bwd, 11)
```

## Best Subset Selection Summary of Output

### Question 4.1

This line of code determines the best variable subset selection using RSS. The default for regsubsets() only generates results for models with up to 8 variables. The function nvmax() overides this default. In this case, the number of variables allowed for the best variable selection is 13. The 13 variables selected for best model fit include crim, zn, indus, chas, nox, rm, age, dis, rad, tax, ptratio, black, lstat, and medv.

### Question 4.2

This line of code prints the best variable selection for each model size. For an 8 variable model, the best variables are zn, chas, nox, rm, dis, ptratio, black, and lstat.

### Question 4.3

This line of code produces the column names for the regfit.full model.

### Question 4.4

This line of code specifies the plot matrix parameters for the plot matrix to be generated in the proceeding lines of code. In this case, a 2x2 plot matrix is called for.

### Question 4.5

These lines of codes produce four different plots. The plots indicate the best number of variables to select for the model based on values for RSS, adjusted r2, Mallow's Cp, and BIC, respectively. According to the plots produced, the best number of variables to include is 11.

### Question 4.6

This line of code denotes that the value for adjusted r2 occurs with an 11 variable model.

### Question 4.7

This line of code denotes that the value for Mallow's Cp occurs with an 11 variable model.


### Question 4.8

This line of code denotes that the value for BIC occurs with an 11 variable model.

### Question 4.9

These plots visually plot variable significance based on their respective RSS, adjusted r2, Mallow's Cp, and BIC values. According to these plots, the most significant variables are rm and lstat.

### Question 4.10

By running the lines of code for questions 4.6 through 4.8, an 11 variable model is determined to be the best model.

### Question 6

The best variable for a 13 variable model determined using forward selection include: crim, zn, indus, chas, nox, rm, age, dis, rad, tax, ptratio, black, and lstat. For an 11 variable model, which was determined to be the best model in Question 4.10, forward selection determined crim, zn, chas, nox, rm, dis, rad, tax, ptratio, black, and lstat to be the best variables to include in the model.

The best variable for a 13 variable model determined using backward selection include all of the variables selected for the best 13 variable model using forward selection. Backward selection also determined crim, zn, chas, nox, rm, dis, rad, tax, ptratio, black, and lstat to be the best variables to include in the model.

# Section 2: Unsupervised Learning

## Principal Components Analysis

```{r}
states <- row.names (USArrests)
states
names(USArrests)

apply(USArrests, 2, mean)
apply(USArrests , 2, var)

pr.out <- prcomp (USArrests, scale = TRUE)
names(pr.out)
pr.out$center
pr.out$rotation

dim(pr.out$x)
biplot(pr.out, scale = 0)
pr.out$rotation = -pr.out$rotation
pr.out$x = -pr.out$x
biplot(pr.out, scale = 0)

pr.out$sdev
pr.var <- pr.out$sdev^2
pr.var
pve <- pr.var / sum (pr.var)
pve

par(mfrow = c(1, 2))
plot(pve, xlab = " Principal Component", ylab = " Proportion of Variance Explained ", ylim = c(0, 1), type = "b")
plot(cumsum (pve), xlab = " Principal Component ", ylab = " Cumulative Proportion of Variance Explained ", ylim = c(0, 1), type = "b")
```
## Principal Component Analysis Summary of Output

### Question 7

This R code chunk determines principal components using the prcomp() function. In this case, the principal components are determined for USArrests dataset using a four dimensional model that includes the variables Murder, Assault, UrbanPop, and Rape. 

Using the apply() function, the mean and variance for each of the variables was determined to be as follows: Murder (mean = 7..79, var = 18.97), Assault (mean = 170.76, var = 6945.17), UrbanPop (mean = 65.54, var = 209.52), and Rape (mean = 21.23, var = 87.73). Each variable was scaled by setting scale = TRUE in the model since the values for the variables are in different units. Scaling the variables sets mean = 0 and var = 1 for each of the variables through standardization of the variable values.

The column names for the pr.out model are sdev, rotation, center, scale, and x. The column of interest in determining the principal components for the model is the rotation column. According to the calculated values for rotation, the principal components are as follows: 1st principal component (PC1) = Murder, Assault, and Rape; 2nd principal component (PC2) = UrbanPop. 

The plot produced by this R Code chunk plots PC1 vs, PC2 for each state. The arrows on the plot for Murder, Assault, and Rape point left in an upwards direction. Being that the principal component loadings for each of the variables is negative, states that fall to the left of the arrows for these components are considered to have higher rates than the states that fall to the right of the arrows. Meanwhile, the arrow for PC2 (UrbanPop) points downwards meaning that below the arrow have the highest urban population while states above the arrow have lower urban populations. The second plot produced by the R code chunk simply reorients the first plot by using the negative of the rotation values, which results in positive values.

The R code chunk also calculates the variance for each principal component, and then calculates the porpotion of variance explained by each component. The PVE value for PC1 is 0.62 and is 0.25 for PC2, meaning that the variance for the variables Murder, Rape, Assault, and UrbanPop explain 87% of the variance in the model. The plot matrix produced by the subsequent lines of code reflect the PVE and cumulative PVE by each principal component. The function cumsum() then computes the cumulative sum of the elements of vector, a. 

## K-Means Clustering

```{r}
set.seed (2)
x <- matrix ( rnorm (50 * 2), ncol = 2)
x[1:25, 1] <- x[1:25, 1] + 3
x[1:25, 2] <- x[1:25, 2] - 4

km.out <- kmeans (x, 2, nstart = 20)

km.out$cluster
 
par (mfrow = c(1, 2))
plot (x, col = (km.out$cluster + 1),
main = "K- Means Clustering Results with K = 2",
xlab = "", ylab = "", pch = 20, cex = 2)

set.seed (4)
km.out <- kmeans (x, 3, nstart = 20)
km.out

plot (x, col = (km.out$cluster + 1),
main = "K- Means Clustering Results with K = 3",
xlab = "", ylab = "", pch = 20, cex = 2)

set.seed (4)
km.out <- kmeans (x, 3, nstart = 1)
km.out$tot.withinss

km.out <- kmeans (x, 3, nstart = 20)
km.out$tot.withinss
```


## K-Means Clustering Summary of Output

### Question 8

This R code chunk performs K-means clustering for different numbers of clusters. The first model performs K-means clustering using just two clusters. The plot produced for this model depicts an upwards diagonal split of the data. The two clusters of observations are indicated by the colors red and green. The model that uses three clusters adds an additional diagonal split to the data, according to the graph produced for the model. This additional "split" or cluster in the data results in nearly halving the original size of the red cluster and the loss of just two observation from the green cluster. This additional partioning of the data results in a blue cluster of data between the red and green clusters. The within cluster sum of squares was calculated to be 79.3% which can also be interpreted as the model's prediction accuracy rate. The last five lines of code compare the total within values between models where nstart = 1 and nstart = 20. The result shows that setting nstart = 20 produces a smaller total within values, which is preferable.

## Hierarchical Clustering

```{r}
hc.complete <- hclust ( dist (x), method = "complete")
hc.average <- hclust ( dist (x), method = "average")
 hc.single <- hclust ( dist (x), method = "single")
 
par (mfrow = c(1, 3))
plot (hc.complete, main = " Complete Linkage ", xlab = "", sub = "", cex = .9)
plot (hc.average , main = " Average Linkage ", xlab = "", sub = "", cex = .9)
plot (hc.single, main = " Single Linkage ", xlab = "", sub = "", cex = .9)

cutree (hc.complete, 2)
cutree (hc.average, 2)
cutree (hc.single, 2)

cutree (hc.single, 4)

xsc <- scale (x)
plot ( hclust ( dist (xsc), method = "complete") , main = "Hierarchical Clustering with Scaled Features")

x <- matrix ( rnorm (30 * 3), ncol = 3)
dd <- as.dist (1 - cor (t(x)))
plot ( hclust (dd, method = "complete") , main = " Complete Linkage with Correlation - Based Distance ", xlab = "", sub = "")

```

## Hierarchical Clustering Summary of Output

### Question 9

This R code chunk two different plot matrices depicting a total of five different hierarchical clustering trees. The first matrix contains trees for hierarchical clustering performed using complete, average, and single linkage. Each of these trees have been cut into two clusters, however the output for the single linkage tree produced using the cutree() function reveals that single linkage is not appropriate being that it separates only one observation into the second cluster. The same result is produced when the tree is cut into four clusters using single linkage, which separates only one observation into the fourth cluster.

The second plot matrix includes trees for clustering with scaled features using complete linkage and clustering with correlation based distance using complete linkage. Based on the final tree, produced after scaling has occurred, no true clusters exist within the dataset.

# References

James, G., Witten, D., Hastie, T., Tibshirani, R. (2021). Heart.csv [Data set]. https://www.statlearning.com/resources-second-edition